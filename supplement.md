I hope that you will take part in contributing to the project for the entry on Archive. As you
can see even further below, each topic will have five elements connected to them: 1) A brief
reflection on how digital methods could be of use. 2) A suggestion for 1-3 elementary
approaches. 3) A suggestion for 1-2 advanced approaches. 4) A short description to online tools
and/or code. 5) References to articles and books that have already done work in this area with
computational methods.  

1. An archive essentially constitutes a collection of documents, which,
with some work, can become a corpus or a dataset, to be used for further research. As a thought
experiment, I suggest you reflect on word cognates from other fields that denote roughly a
similar idea of a collection. Consider also the differences between an archive and a dataset
derived from it. Where we normally look for individual insights or discoveries in an archive,
computational tools allow us to manipulate it as a single unit, to extract trends, and to build
models that encompass multiple documents. In doing so, a researcher must not treat archives as
neutral or natural reflections of the times past. For example, the papers of Toni Morrison at
Princeton provide a window onto the author's intellectual life as narrated through her letters
and manuscripts, but not book reviews or scholarly articles. The understanding of an archive's
history—institutional, political, cultural—will ensure that any claims deriving from the
underlying documents can better correspond to the resulting insight. Computational work within
archives, in other words, must proceed from a contextual understanding of their history.

2/3/4. A great variety of computational tools are available for the work with textual or image
archives. (Working across media, however, can pose a significant challenge.) It is always wise
to begin with exploratory, descriptive tools. If you are interested in the concept of "justice"
in the 19th century, for example, you can begin by asking what words were used to describe
justice? How often to they appear? How does the lexicon surrounding these concepts change over
time or in response to specific events? More advanced approaches would include state-of-the
methods such as topic modeling, hypothesis testing, or network analysis. Initial experiments
with an archive can and should be done by hand, using paper and pencil or chalk and blackboard.
With time, researchers can progress to simple command-line tools, such as `grep`, `sort`, and
`uniq`. Further, an ecosystem of powerful libraries in Python and R languages exists to support
computational analysis of text, sound, and image archives.

For examples of research done in this space see: 

Smith, David A., Ryan Cordell, and Abby Mullen. “Computational Methods for Uncovering Reprinted
Texts in Antebellum Newspapers.” American Literary History 27, no. 3 (September 1, 2015):
E1–15. 

Klein, Lauren F., Jacob Eisenstein, and Iris Sun. “Exploratory Thematic Analysis for Digitized
Archival Collections.” Digital Scholarship in the Humanities 30, no. suppl_1 (December 1,
2015): i130–41. 

Aljoe, Nicole N., Elizabeth Maddock Dillon, Benjamin J. Doyle, and Elizabeth Hopwood. “Obeah
and the Early Caribbean Digital Archive.” Atlantic Studies 12, no. 2 (April 3, 2015): 258–66. 

Tangherlini, Timothy R., and Peter Leonard. “Trawling in the Sea of the Great Unread:
Sub-Corpus Topic Modeling and Humanities Research.” Poetics, Topic Models and the Cultural
Sciences, 41, no. 6 (December 1, 2013): 725–49.
